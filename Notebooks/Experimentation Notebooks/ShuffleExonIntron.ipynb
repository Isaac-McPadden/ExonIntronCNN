{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran shuffles and saves in a separate notebook before splitting test_dataset_from_tfrecords into two functions that did different things.\n",
    "\n",
    "shuffle_dataset_from_tfrecords is effectively an experimental version of what became build_dataset_from_tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 00:51:13.839378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-31 00:51:13.856016: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-31 00:51:13.860967: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-31 00:51:13.873058: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-31 00:51:14.619020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import threading\n",
    "import concurrent.futures as cf\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model, layers, metrics, losses, callbacks, optimizers, models, utils\n",
    "from keras import backend as K\n",
    "import gc\n",
    "import keras_tuner as kt\n",
    "from pyfaidx import Fasta\n",
    "\n",
    "K.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "datasets_path = \"../../Datasets/\"\n",
    "models_path = \"../../Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset_from_tfrecords(\n",
    "    tfrecord_pattern,\n",
    "    batch_size=32,\n",
    "    compression_type='GZIP',\n",
    "    shuffle_buffer=100000,\n",
    "    # shuffle_buffer_small=500\n",
    "):\n",
    "    files = tf.data.Dataset.list_files(tfrecord_pattern, shuffle=True)\n",
    "    \n",
    "    dataset = files.interleave(\n",
    "        lambda fname: tf.data.TFRecordDataset(fname, compression_type=compression_type),\n",
    "        cycle_length=4,        # how many files to read in parallel\n",
    "        block_length=1,         # how many records to read from each file before switching\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "    \n",
    "    # Shuffle at the record level\n",
    "    dataset = dataset.shuffle(shuffle_buffer, reshuffle_each_iteration=True)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.shuffle(10*batch_size, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.unbatch()\n",
    "    # dataset = dataset.shuffle(shuffle_buffer_small, reshuffle_each_iteration=True)\n",
    "    \n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738309890.744991    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738309890.805764    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738309890.805825    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738309890.810829    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738309890.810960    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738309890.810991    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738309891.042480    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738309891.042554    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-31 00:51:31.042565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1738309891.042616    1215 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-31 00:51:31.042639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8695 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "2025-01-31 00:51:54.507719: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 75279 of 100000\n",
      "2025-01-31 00:51:59.383578: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "2025-01-31 00:52:02.821641: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "2025-01-31 01:00:05.208996: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "tfrecord_pattern = datasets_path + \"Shuffled_again/shuffled_shard_*.tfrecord.gz\"\n",
    "\n",
    "# Shuffled serialized dataset\n",
    "ssds = shuffle_dataset_from_tfrecords(tfrecord_pattern,\n",
    "                                  batch_size=32, compression_type='GZIP',\n",
    "                                  shuffle_buffer=100000)\n",
    "\n",
    "idx_ssds = ssds.enumerate()\n",
    "\n",
    "# if not os.path.exists(\"Last_shuffle\"):\n",
    "#     os.makedirs(\"Last_shuffle\")\n",
    "\n",
    "# num_shards = 4\n",
    "# writers = [\n",
    "#     tf.io.TFRecordWriter(f\"{datasets_path}Last_shuffle/shuffled_shard_{i}.tfrecord\", options=options)\n",
    "#     for i in range(num_shards)\n",
    "# ]\n",
    "\n",
    "# # Write out round-robin to each shard\n",
    "# for i, serialized_example in idx_ssds:\n",
    "#     shard_index = i.numpy() % num_shards\n",
    "#     writers[shard_index].write(serialized_example.numpy())\n",
    "\n",
    "# # Close all writers\n",
    "# for w in writers:\n",
    "#     w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
