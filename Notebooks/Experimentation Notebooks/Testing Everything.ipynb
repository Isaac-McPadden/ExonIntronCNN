{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_fabricate_vectors.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IEModules.Helper_Functions import fabricate_vectors_for_f1\n",
    "from IEModules.Custom_Metrics import CustomNoBackgroundF1Score\n",
    "\n",
    "@pytest.mark.parametrize(\"target, with_bg\", [\n",
    "    (0.30, True),\n",
    "    (0.55, True),\n",
    "    (0.87, True),\n",
    "    (0.20, False),\n",
    "    (0.77, False),\n",
    "    (1.00, False),\n",
    "])\n",
    "def test_fabricated_f1(target, with_bg):\n",
    "    y_true, y_pred = fabricate_vectors_for_f1(target,\n",
    "                                              length=200,\n",
    "                                              include_background=with_bg,\n",
    "                                              seed=42)\n",
    "    metric = CustomNoBackgroundF1Score(\n",
    "        num_classes=5,   # always 5, the metric strips bg if present\n",
    "        name=\"nb_f1\"\n",
    "    )\n",
    "    metric.update_state(tf.constant(y_true), tf.constant(y_pred))\n",
    "    realised = metric.result().numpy()\n",
    "    # allow tiny float error\n",
    "    assert np.isclose(realised, target, atol=1e-6), \\\n",
    "        f\"wanted {target}, got {realised}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IEModules.Helper_Functions import fabricate_vectors_for_f1\n",
    "from IEModules.Custom_Metrics   import CustomNoBackgroundF1Score\n",
    "import tensorflow as tf\n",
    "\n",
    "yt, yp = fabricate_vectors_for_f1(0.77, 200, include_background=True, seed=1)\n",
    "metric = CustomNoBackgroundF1Score(num_classes=5)\n",
    "metric.update_state(tf.constant(yt), tf.constant(yp))\n",
    "print(\"Realised F1 =\", round(metric.result().numpy(), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper_Functions.py  (add below the previous helper)\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def fabricate_vectors_for_f1_and_acc(target_f1: float,\n",
    "                                     target_acc: float,\n",
    "                                     length: int = 200,\n",
    "                                     include_background: bool = True,\n",
    "                                     focus_class: int = 1,\n",
    "                                     seed: int | None = None,\n",
    "                                     tol: float = 1e-12\n",
    "                                     ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build y_true / y_pred whose **weighted** CustomNoBackgroundF1Score equals\n",
    "    `target_f1` *and* whose overall accuracy equals `target_acc`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_f1, target_acc : floats in (0,1]\n",
    "    length                : number of rows (>=200 recommended)\n",
    "    include_background    : 5‑column if True else 4‑column\n",
    "    focus_class           : which target column (1…4) carries all positives\n",
    "    seed                  : RNG seed\n",
    "    tol                   : floating‑point tolerance for the final checks\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_true, y_pred : float32 arrays shaped [length, num_classes]\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError if the pair (F1,acc) is infeasible with the chosen `length`.\n",
    "    \"\"\"\n",
    "    if not (0 < target_f1 <= 1) or not (0 < target_acc <= 1):\n",
    "        raise ValueError(\"F1 and accuracy must lie in (0,1].\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_classes = 5 if include_background else 4\n",
    "    pos_col   = focus_class if include_background else focus_class - 1\n",
    "\n",
    "    # ----------  solve for integer TP  ----------\n",
    "    denom = 2 * (1 - target_f1)\n",
    "    TP_est = length * target_f1 * (1 - target_acc) / denom\n",
    "    TP_int = round(TP_est)\n",
    "\n",
    "    # slide ±1 around the rounded value until everything fits\n",
    "    found = False\n",
    "    for TP in range(max(0, TP_int-2), TP_int+3):\n",
    "        S  = 2 * TP * (1/target_f1 - 1)             # FP + FN\n",
    "        TN = int(round(target_acc * length - TP))   # from accuracy\n",
    "\n",
    "        if (abs(target_acc - (TP+TN)/length) < tol and\n",
    "            abs(target_f1  - (2*TP)/(2*TP+S)) < tol and\n",
    "            0 <= TN <= length and\n",
    "            S.is_integer()):\n",
    "            FP = int(S // 2)\n",
    "            FN = int(S - FP)\n",
    "            if TP + FP + FN + TN == length:\n",
    "                found = True\n",
    "                break\n",
    "    if not found:\n",
    "        raise ValueError(\"Chosen F1/accuracy not realisable with length {}\"\n",
    "                         .format(length))\n",
    "\n",
    "    # ----------  materialise the rows ----------\n",
    "    y_true = np.zeros((length, n_classes), dtype=np.float32)\n",
    "    y_pred = np.zeros_like(y_true)\n",
    "    rows = rng.permutation(length)\n",
    "    idx = 0\n",
    "    for _ in range(TP):\n",
    "        r = rows[idx]; idx += 1\n",
    "        y_true[r, pos_col] = y_pred[r, pos_col] = 1\n",
    "    for _ in range(FN):\n",
    "        r = rows[idx]; idx += 1\n",
    "        y_true[r, pos_col] = 1\n",
    "    for _ in range(FP):\n",
    "        r = rows[idx]; idx += 1\n",
    "        if include_background:\n",
    "            y_true[r, 0] = 1\n",
    "        y_pred[r, pos_col] = 1\n",
    "    for _ in range(TN):\n",
    "        r = rows[idx]; idx += 1\n",
    "        if include_background:\n",
    "            y_true[r, 0] = 1\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IEModules.Custom_Metrics import CustomNoBackgroundF1Score\n",
    "import tensorflow as tf\n",
    "from IEModules.Helper_Functions import fabricate_vectors_for_f1_and_acc\n",
    "\n",
    "F1_target, acc_target = 0.78, 0.60\n",
    "yt, yp = fabricate_vectors_for_f1_and_acc(F1_target, acc_target,\n",
    "                                          length=200,\n",
    "                                          include_background=True,\n",
    "                                          seed=123)\n",
    "\n",
    "nb_f1 = CustomNoBackgroundF1Score(num_classes=5)\n",
    "nb_f1.update_state(tf.constant(yt), tf.constant(yp))\n",
    "print(\"F1 :\", nb_f1.result().numpy())\n",
    "\n",
    "accuracy = ( (yp >= 0.5) == (yt == 1) ).mean()\n",
    "print(\"acc:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchModelCheckpoint(callbacks.ModelCheckpoint):\n",
    "    \"\"\"\n",
    "    A ModelCheckpoint that also saves immediately after the final training\n",
    "    batch of each epoch (i.e. before validation begins), using the same\n",
    "    filepath template and arguments as the standard checkpoint.\n",
    "    \"\"\"\n",
    "    def __init__(self, filepath, steps_per_epoch, logs=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath: same template you’d pass to ModelCheckpoint\n",
    "                      (e.g. \".../epoch-{epoch:03d}.keras\")\n",
    "            steps_per_epoch: number of train batches per epoch\n",
    "            **kwargs: all the same keyword args you’d pass to ModelCheckpoint\n",
    "        \"\"\"\n",
    "        super().__init__(filepath, **kwargs)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self._current_epoch = None\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self._cur_epoch = epoch\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch + 1 == self.steps_per_epoch:\n",
    "            # Keras 3 signature: epoch, batch, logs\n",
    "            self._save_model(epoch=self._cur_epoch,\n",
    "                             batch=batch,\n",
    "                             logs=logs or {})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
