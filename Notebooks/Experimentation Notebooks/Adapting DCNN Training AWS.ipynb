{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be2eef24-0682-4300-9a08-ff5c8d4cb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c16590ae-1f18-4177-8c03-cf3541a766f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker, boto3, json\n",
    "# from sagemaker.session import Session\n",
    "\n",
    "# sagemaker_session = Session()\n",
    "# aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "# aws_region = boto3.Session().region_name\n",
    "# sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa955e9c-9915-418c-aee4-6a1dc22d14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_bucket = \"<BUCKET ID HERE>\"\n",
    "# s3 = boto3.client(\"s3\")\n",
    "# s3.download_file(s3_bucket, \"TestValTrain/val.tfrecord.gz\", \"val.tfrecord.gz\")\n",
    "# s3.download_file(s3_bucket, \"TestValTrain/test.tfrecord.gz\", \"test.tfrecord.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831313b-84c4-4c12-99ca-082e6b3e94aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import threading\n",
    "import concurrent.futures as cf\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model, layers, metrics, losses, callbacks, optimizers, models, utils\n",
    "from keras import backend as K\n",
    "import gc\n",
    "import keras_tuner as kt\n",
    "from pyfaidx import Fasta\n",
    "\n",
    "K.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "datasets_path = \"../../Datasets/\"\n",
    "models_path = \"../../Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da3e7aaf-9a42-4491-9504-389ecce681f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.register_keras_serializable()\n",
    "class CustomNoBackgroundF1Score(metrics.Metric):\n",
    "    def __init__(self, num_classes, average='weighted', threshold=0.5, name='no_background_f1', **kwargs):\n",
    "        \"\"\"\n",
    "        Custom F1 score metric that only considers non-dominant classes (ignoring index 0).\n",
    "        \n",
    "        This version is designed for multi-encoded labels where:\n",
    "          - The dominant class (index 0) is represented as a hard label [1, 0, 0, ...]\n",
    "          - For non-dominant classes (indices 1 to num_classes-1), only an exact label of 1 is considered positive.\n",
    "            (Any partial credit/smoothed values below 1 are treated as 0.)\n",
    "          - Predictions are thresholded (default threshold = 0.5) to decide 1 vs. 0.\n",
    "        \n",
    "        Args:\n",
    "            num_classes (int): Total number of classes.\n",
    "            average (str): 'weighted' (default) to weight by support or 'macro' for a simple average.\n",
    "            threshold (float): Threshold on y_pred to decide a positive (default 0.5).\n",
    "            name (str): Name of the metric.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "        \"\"\"\n",
    "        super(CustomNoBackgroundF1Score, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.threshold = threshold\n",
    "        if average not in ['weighted', 'macro']:\n",
    "            raise ValueError(\"average must be 'weighted' or 'macro'\")\n",
    "        self.average = average\n",
    "\n",
    "        # Create state variables to accumulate counts for each class.\n",
    "        # We use a vector of length num_classes but we will update only indices 1...num_classes-1.\n",
    "        self.true_positives = self.add_weight(\n",
    "            name='tp', shape=(num_classes,), initializer='zeros', dtype=tf.float32\n",
    "        )\n",
    "        self.false_positives = self.add_weight(\n",
    "            name='fp', shape=(num_classes,), initializer='zeros', dtype=tf.float32\n",
    "        )\n",
    "        self.false_negatives = self.add_weight(\n",
    "            name='fn', shape=(num_classes,), initializer='zeros', dtype=tf.float32\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Updates the metric state.\n",
    "        \n",
    "        Args:\n",
    "            y_true: Tensor of shape (batch_size, num_classes). These are multi-encoded labels.\n",
    "                    For non-dominant classes, a label is considered positive only if it is exactly 1.\n",
    "            y_pred: Tensor of shape (batch_size, num_classes) with predictions (e.g. probabilities).\n",
    "            sample_weight: Optional sample weights.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Flatten all dimensions except the last one (which should be num_classes).\n",
    "        y_true = tf.reshape(y_true, [-1, self.num_classes])\n",
    "        y_pred = tf.reshape(y_pred, [-1, self.num_classes])\n",
    "        \n",
    "        # We want to ignore the dominant class (index 0) and work on classes 1...num_classes-1.\n",
    "        # Assume y_true and y_pred are both of shape (batch_size, num_classes).\n",
    "        y_true_non_dominant = y_true[:, 1:]\n",
    "        y_pred_non_dominant = y_pred[:, 1:]\n",
    "        \n",
    "        # For ground truth: treat a class as positive only if its value is exactly 1.\n",
    "        one_value = tf.cast(1.0, dtype=y_true_non_dominant.dtype)\n",
    "        y_true_bin = tf.cast(tf.equal(y_true_non_dominant, one_value), tf.int32)\n",
    "        # For predictions: apply thresholding.\n",
    "        y_pred_bin = tf.cast(y_pred_non_dominant >= self.threshold, tf.int32)\n",
    "        \n",
    "        # (Optionally) apply sample weighting.\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, tf.int32)\n",
    "            sample_weight = tf.reshape(sample_weight, (-1, 1))\n",
    "            y_true_bin = y_true_bin * sample_weight\n",
    "            y_pred_bin = y_pred_bin * sample_weight\n",
    "        \n",
    "        # Compute per-class true positives, false positives, and false negatives for non-dominant classes.\n",
    "        tp = tf.reduce_sum(tf.cast(y_true_bin * y_pred_bin, tf.float32), axis=0)\n",
    "        fp = tf.reduce_sum(tf.cast((1 - y_true_bin) * y_pred_bin, tf.float32), axis=0)\n",
    "        fn = tf.reduce_sum(tf.cast(y_true_bin * (1 - y_pred_bin), tf.float32), axis=0)\n",
    "        \n",
    "        # Our state variables have length num_classes. We want to update only indices 1... with our computed values.\n",
    "        zeros = tf.zeros([1], dtype=tf.float32)\n",
    "        tp_update = tf.concat([zeros, tp], axis=0)\n",
    "        fp_update = tf.concat([zeros, fp], axis=0)\n",
    "        fn_update = tf.concat([zeros, fn], axis=0)\n",
    "        \n",
    "        self.true_positives.assign_add(tp_update)\n",
    "        self.false_positives.assign_add(fp_update)\n",
    "        self.false_negatives.assign_add(fn_update)\n",
    "\n",
    "    def result(self):\n",
    "        \"\"\"\n",
    "        Computes the F1 score over the non-dominant classes (indices 1...num_classes-1).\n",
    "        \"\"\"\n",
    "        # Select non-dominant classes only.\n",
    "        tp = self.true_positives[1:]\n",
    "        fp = self.false_positives[1:]\n",
    "        fn = self.false_negatives[1:]\n",
    "        \n",
    "        precision = tf.math.divide_no_nan(tp, tp + fp)\n",
    "        recall = tf.math.divide_no_nan(tp, tp + fn)\n",
    "        f1 = tf.math.divide_no_nan(2 * precision * recall, precision + recall)\n",
    "        \n",
    "        if self.average == 'weighted':\n",
    "            support = tp + fn\n",
    "            weighted_f1 = tf.reduce_sum(f1 * support) / (tf.reduce_sum(support) + K.epsilon())\n",
    "            return weighted_f1\n",
    "        else:  # macro\n",
    "            return tf.reduce_mean(f1)\n",
    "\n",
    "    def reset_states(self):\n",
    "        \"\"\"\n",
    "        Resets all of the metric state variables.\n",
    "        \"\"\"\n",
    "        for v in self.variables:\n",
    "            v.assign(tf.zeros_like(v))\n",
    "            \n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Returns the configuration of the metric, so it can be recreated later.\n",
    "        \"\"\"\n",
    "        config = super(CustomNoBackgroundF1Score, self).get_config()\n",
    "        config.update({\n",
    "            'num_classes': self.num_classes,\n",
    "            'average': self.average,\n",
    "            'threshold': self.threshold,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fbbea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.register_keras_serializable()\n",
    "class CustomBackgroundOnlyF1Score(metrics.Metric):\n",
    "    def __init__(self, num_classes, average='weighted', threshold=0.5, name='background_only_f1', **kwargs):\n",
    "        \"\"\"\n",
    "        Custom F1 score metric that only considers the dominant (background) class (index 0).\n",
    "\n",
    "        This metric is designed for multi-encoded labels where:\n",
    "          - The dominant class (index 0) aka background is represented as a hard label [1, 0, 0, ...].\n",
    "          - For the dominant class, a label is considered positive only if it is exactly 1.\n",
    "          - Predictions are thresholded (default threshold = 0.5) to decide 1 vs. 0.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Total number of classes.\n",
    "            average (str): 'weighted' (default) or 'macro'. (Since only one class is considered, this\n",
    "                           choice won’t make much difference.)\n",
    "            threshold (float): Threshold on y_pred to decide a positive (default 0.5).\n",
    "            name (str): Name of the metric.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "        \"\"\"\n",
    "        super(CustomBackgroundOnlyF1Score, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.threshold = threshold\n",
    "        if average not in ['weighted', 'macro']:\n",
    "            raise ValueError(\"average must be 'weighted' or 'macro'\")\n",
    "        self.average = average\n",
    "\n",
    "        # We still create vectors of length num_classes, but will only update index 0.\n",
    "        self.true_positives = self.add_weight(\n",
    "            name='tp', shape=(num_classes,), initializer='zeros', dtype=tf.float32\n",
    "        )\n",
    "        self.false_positives = self.add_weight(\n",
    "            name='fp', shape=(num_classes,), initializer='zeros', dtype=tf.float32\n",
    "        )\n",
    "        self.false_negatives = self.add_weight(\n",
    "            name='fn', shape=(num_classes,), initializer='zeros', dtype=tf.float32\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Updates the metric state using only the dominant class (index 0).\n",
    "\n",
    "        Args:\n",
    "            y_true: Tensor of shape (batch_size, num_classes). For the dominant class,\n",
    "                    a label is considered positive only if it is exactly 1.\n",
    "            y_pred: Tensor of shape (batch_size, num_classes) (e.g. probabilities).\n",
    "            sample_weight: Optional sample weights.\n",
    "        \"\"\"\n",
    "        # Reshape to (-1, num_classes) in case additional dimensions exist.\n",
    "        y_true = tf.reshape(y_true, [-1, self.num_classes])\n",
    "        y_pred = tf.reshape(y_pred, [-1, self.num_classes])\n",
    "\n",
    "        # Extract the dominant class (index 0)\n",
    "        y_true_dominant = y_true[:, 0]\n",
    "        y_pred_dominant = y_pred[:, 0]\n",
    "\n",
    "        # For ground truth, treat as positive only if exactly equal to 1.\n",
    "        one_value = tf.cast(1.0, dtype=y_true_dominant.dtype)\n",
    "        y_true_bin = tf.cast(tf.equal(y_true_dominant, one_value), tf.float32)\n",
    "\n",
    "        # For predictions, apply thresholding.\n",
    "        y_pred_bin = tf.cast(y_pred_dominant >= self.threshold, tf.float32)\n",
    "\n",
    "        # Optionally apply sample weighting.\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, tf.float32)\n",
    "            sample_weight = tf.reshape(sample_weight, [-1])\n",
    "            y_true_bin = y_true_bin * sample_weight\n",
    "            y_pred_bin = y_pred_bin * sample_weight\n",
    "\n",
    "        # Compute true positives, false positives, and false negatives for the dominant class.\n",
    "        tp = tf.reduce_sum(y_true_bin * y_pred_bin)\n",
    "        fp = tf.reduce_sum((1 - y_true_bin) * y_pred_bin)\n",
    "        fn = tf.reduce_sum(y_true_bin * (1 - y_pred_bin))\n",
    "\n",
    "        # We create update vectors that place the computed scalar at index 0 and zeros elsewhere.\n",
    "        zeros = tf.zeros([self.num_classes - 1], dtype=tf.float32)\n",
    "        tp_update = tf.concat([[tp], zeros], axis=0)\n",
    "        fp_update = tf.concat([[fp], zeros], axis=0)\n",
    "        fn_update = tf.concat([[fn], zeros], axis=0)\n",
    "\n",
    "        self.true_positives.assign_add(tp_update)\n",
    "        self.false_positives.assign_add(fp_update)\n",
    "        self.false_negatives.assign_add(fn_update)\n",
    "\n",
    "    def result(self):\n",
    "        \"\"\"\n",
    "        Computes the F1 score for the dominant (background) class (index 0).\n",
    "        \"\"\"\n",
    "        tp = self.true_positives[0]\n",
    "        fp = self.false_positives[0]\n",
    "        fn = self.false_negatives[0]\n",
    "\n",
    "        precision = tf.math.divide_no_nan(tp, tp + fp)\n",
    "        recall = tf.math.divide_no_nan(tp, tp + fn)\n",
    "        f1 = tf.math.divide_no_nan(2 * precision * recall, precision + recall)\n",
    "\n",
    "        # Although averaging is not critical with a single class, we mirror the interface.\n",
    "        if self.average == 'weighted':\n",
    "            support = tp + fn\n",
    "            weighted_f1 = tf.math.divide_no_nan(f1 * support, support + K.epsilon())\n",
    "            return weighted_f1\n",
    "        else:  # macro\n",
    "            return f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        \"\"\"\n",
    "        Resets all of the metric state variables.\n",
    "        \"\"\"\n",
    "        for v in self.variables:\n",
    "            v.assign(tf.zeros_like(v))\n",
    "            \n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Returns the configuration of the metric, so it can be recreated later.\n",
    "        \"\"\"\n",
    "        config = super(CustomBackgroundOnlyF1Score, self).get_config()\n",
    "        config.update({\n",
    "            'num_classes': self.num_classes,\n",
    "            'average': self.average,\n",
    "            'threshold': self.threshold,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f2373b0-f99f-4019-a35a-94d810e9bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(y_true, y_pred):\n",
    "#         # Prevent log(0) issues.\n",
    "#         epsilon = K.epsilon()\n",
    "#         y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "#         # Flatten all dimensions except the last one (which should represent the classes).\n",
    "#         y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n",
    "#         y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "        \n",
    "#         # Compute the standard element-wise binary crossentropy.\n",
    "#         base_loss = - (y_true * tf.math.log(y_pred) +\n",
    "#                        (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "        \n",
    "#         # Determine the number of classes.\n",
    "#         num_classes = tf.shape(y_true)[1]\n",
    "        \n",
    "#         # Create a one-hot mask for the dominant class.\n",
    "#         # This yields a tensor of shape (num_classes,).\n",
    "#         dominant_mask = tf.one_hot(dominant_class_index, depth=num_classes, dtype=y_true.dtype)\n",
    "#         non_dominant_mask = 1 - dominant_mask\n",
    "        \n",
    "#         # --- Dominant Class Weighting ---\n",
    "#         # For the dominant class: if y_true == 1, use dominant_correct_multiplier; otherwise, use dominant_incorrect_multiplier.\n",
    "#         dominant_true = y_true[:, dominant_class_index]  # Shape: (N,)\n",
    "#         dominant_weight = tf.where(tf.equal(dominant_true, 1.0),\n",
    "#                                    dominant_correct_multiplier,\n",
    "#                                    dominant_incorrect_multiplier)  # Shape: (N,)\n",
    "#         dominant_weight = tf.expand_dims(dominant_weight, axis=1)  # Shape: (N, 1)\n",
    "        \n",
    "#         # --- Non-Dominant Class Weighting ---\n",
    "#         # For non-dominant classes:\n",
    "#         #   - If y_true == 1, use other_class_multiplier.\n",
    "#         #   - If 0 < y_true < 1 (i.e. a smoothed value), use smoothing_multiplier.\n",
    "#         #   - Otherwise (y_true == 0) use 1.\n",
    "#         non_dominant_weight = tf.where(\n",
    "#             tf.equal(y_true, 1.0),\n",
    "#             other_class_multiplier,\n",
    "#             tf.where(tf.greater(y_true, 0.0),\n",
    "#                      smoothing_multiplier,\n",
    "#                      1.0)\n",
    "#         )\n",
    "        \n",
    "#         # Reshape the masks so they broadcast properly with the batch.\n",
    "#         dominant_mask = tf.reshape(dominant_mask, [1, num_classes])\n",
    "#         non_dominant_mask = tf.reshape(non_dominant_mask, [1, num_classes])\n",
    "        \n",
    "#         # Combine the weights: for each sample and each class,\n",
    "#         # the weight is dominant_weight for the dominant class and non_dominant_weight for the others.\n",
    "#         weights = dominant_mask * dominant_weight + non_dominant_mask * non_dominant_weight\n",
    "        \n",
    "#         # Compute the weighted loss.\n",
    "#         weighted_loss = base_loss * weights\n",
    "#         return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# def custom_binary_crossentropy_loss(\n",
    "#     dominant_class_index=0,\n",
    "#     dominant_correct_multiplier=0.07,    # Reward factor when the dominant class is correct\n",
    "#     dominant_incorrect_multiplier=2.5,    # Penalty factor when the dominant class is predicted incorrectly\n",
    "#     other_class_multiplier=2.0,           # Multiplier for non-dominant classes when y_true == 1\n",
    "#     smoothing_multiplier=0.5              # Multiplier for non-dominant classes when y_true is a smoothed value (0 < y_true < 1)\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Returns a custom binary crossentropy loss function that treats the dominant class specially,\n",
    "#     and applies different multipliers for non-dominant classes based on their true label values.\n",
    "\n",
    "#     For the dominant class (specified by dominant_class_index):\n",
    "#       - If y_true == 1, the loss is scaled by dominant_correct_multiplier.\n",
    "#       - Otherwise, it is scaled by dominant_incorrect_multiplier.\n",
    "\n",
    "#     For non-dominant classes:\n",
    "#       - If y_true == 1, the loss is scaled by other_class_multiplier.\n",
    "#       - If 0 < y_true < 1 (e.g. label-smoothed values), the loss is scaled by smoothing_multiplier.\n",
    "#       - If y_true == 0, no additional scaling is applied.\n",
    "\n",
    "#     This version also reshapes the inputs so that it can handle batches with extra dimensions.\n",
    "\n",
    "#     Parameters:\n",
    "#       dominant_class_index (int): Index of the dominant class in the output vector.\n",
    "#       dominant_correct_multiplier (float): Multiplier for the loss when the dominant class is correctly predicted.\n",
    "#       dominant_incorrect_multiplier (float): Multiplier for the loss when the dominant class is incorrectly predicted.\n",
    "#       other_class_multiplier (float): Multiplier for non-dominant classes when the true label is 1.\n",
    "#       smoothing_multiplier (float): Multiplier for non-dominant classes when the true label is a smoothed value (0 < y_true < 1).\n",
    "\n",
    "#     Returns:\n",
    "#       A callable loss function usable with model.compile(loss=...).\n",
    "#     \"\"\"\n",
    "\n",
    "#     def loss(y_true, y_pred):\n",
    "#         # Prevent log(0) issues.\n",
    "#         epsilon = K.epsilon()\n",
    "#         y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "#         # Flatten all dimensions except the last one (which should represent the classes).\n",
    "#         y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n",
    "#         y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "        \n",
    "#         # Compute the standard element-wise binary crossentropy.\n",
    "#         base_loss = - (y_true * tf.math.log(y_pred) +\n",
    "#                        (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "        \n",
    "#         # Determine the number of classes.\n",
    "#         num_classes = tf.shape(y_true)[1]\n",
    "        \n",
    "#         # Create a one-hot mask for the dominant class.\n",
    "#         # This yields a tensor of shape (num_classes,).\n",
    "#         dominant_mask = tf.one_hot(dominant_class_index, depth=num_classes, dtype=y_true.dtype)\n",
    "#         non_dominant_mask = 1 - dominant_mask\n",
    "        \n",
    "#         # --- Dominant Class Weighting ---\n",
    "#         # For the dominant class: if y_true == 1, use dominant_correct_multiplier; otherwise, use dominant_incorrect_multiplier.\n",
    "#         dominant_true = y_true[:, dominant_class_index]  # Shape: (N,)\n",
    "#         dominant_weight = tf.where(tf.equal(dominant_true, 1.0),\n",
    "#                                    dominant_correct_multiplier,\n",
    "#                                    dominant_incorrect_multiplier)  # Shape: (N,)\n",
    "#         dominant_weight = tf.expand_dims(dominant_weight, axis=1)  # Shape: (N, 1)\n",
    "        \n",
    "#         # --- Non-Dominant Class Weighting ---\n",
    "#         # For non-dominant classes:\n",
    "#         #   - If y_true == 1, use other_class_multiplier.\n",
    "#         #   - If 0 < y_true < 1 (i.e. a smoothed value), use smoothing_multiplier.\n",
    "#         #   - Otherwise (y_true == 0) use 1.\n",
    "#         non_dominant_weight = tf.where(\n",
    "#             tf.equal(y_true, 1.0),\n",
    "#             other_class_multiplier,\n",
    "#             tf.where(tf.greater(y_true, 0.0),\n",
    "#                      smoothing_multiplier,\n",
    "#                      1.0)\n",
    "#         )\n",
    "        \n",
    "#         # Reshape the masks so they broadcast properly with the batch.\n",
    "#         dominant_mask = tf.reshape(dominant_mask, [1, num_classes])\n",
    "#         non_dominant_mask = tf.reshape(non_dominant_mask, [1, num_classes])\n",
    "        \n",
    "#         # Combine the weights: for each sample and each class,\n",
    "#         # the weight is dominant_weight for the dominant class and non_dominant_weight for the others.\n",
    "#         weights = dominant_mask * dominant_weight + non_dominant_mask * non_dominant_weight\n",
    "        \n",
    "#         # Compute the weighted loss.\n",
    "#         weighted_loss = base_loss * weights\n",
    "#         return tf.reduce_mean(weighted_loss)\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b355e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.register_keras_serializable()\n",
    "class CustomBinaryCrossentropyLoss(losses.Loss):\n",
    "    def __init__(self,\n",
    "                 dominant_class_index=0,\n",
    "                 dominant_correct_multiplier=0.07,    # Reward factor when the dominant class is correct\n",
    "                 dominant_incorrect_multiplier=2.5,     # Penalty factor when the dominant class is predicted incorrectly\n",
    "                 other_class_multiplier=2.0,            # Multiplier for non-dominant classes when y_true == 1\n",
    "                 smoothing_multiplier=0.5,              # Multiplier for non-dominant classes when y_true is a smoothed value (0 < y_true < 1)\n",
    "                 name=\"custom_binary_crossentropy_loss\",\n",
    "                 reduction=\"sum_over_batch_size\"):\n",
    "        super().__init__(name=name)\n",
    "        self.dominant_class_index = dominant_class_index\n",
    "        self.dominant_correct_multiplier = dominant_correct_multiplier\n",
    "        self.dominant_incorrect_multiplier = dominant_incorrect_multiplier\n",
    "        self.other_class_multiplier = other_class_multiplier\n",
    "        self.smoothing_multiplier = smoothing_multiplier\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Prevent log(0) issues.\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Flatten all dimensions except the last one (which should represent the classes).\n",
    "        y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n",
    "        y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "        \n",
    "        # Compute the standard element-wise binary crossentropy.\n",
    "        base_loss = - (y_true * tf.math.log(y_pred) +\n",
    "                       (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "        \n",
    "        # Determine the number of classes.\n",
    "        num_classes = tf.shape(y_true)[1]\n",
    "        \n",
    "        # Create a one-hot mask for the dominant class.\n",
    "        dominant_mask = tf.one_hot(self.dominant_class_index, depth=num_classes, dtype=y_true.dtype)\n",
    "        non_dominant_mask = 1 - dominant_mask\n",
    "        \n",
    "        # --- Dominant Class Weighting ---\n",
    "        # For the dominant class: if y_true == 1, use dominant_correct_multiplier; otherwise, use dominant_incorrect_multiplier.\n",
    "        dominant_true = y_true[:, self.dominant_class_index]  # Shape: (N,)\n",
    "        dominant_weight = tf.where(tf.equal(dominant_true, 1.0),\n",
    "                                   self.dominant_correct_multiplier,\n",
    "                                   self.dominant_incorrect_multiplier)  # Shape: (N,)\n",
    "        dominant_weight = tf.expand_dims(dominant_weight, axis=1)  # Shape: (N, 1)\n",
    "        \n",
    "        # --- Non-Dominant Class Weighting ---\n",
    "        # For non-dominant classes:\n",
    "        #   - If y_true == 1, use other_class_multiplier.\n",
    "        #   - If 0 < y_true < 1 (i.e. a smoothed value), use smoothing_multiplier.\n",
    "        #   - Otherwise (y_true == 0) use 1.\n",
    "        non_dominant_weight = tf.where(\n",
    "            tf.equal(y_true, 1.0),\n",
    "            self.other_class_multiplier,\n",
    "            tf.where(tf.greater(y_true, 0.0),\n",
    "                     self.smoothing_multiplier,\n",
    "                     1.0)\n",
    "        )\n",
    "        \n",
    "        # Reshape the masks so they broadcast properly.\n",
    "        dominant_mask = tf.reshape(dominant_mask, [1, num_classes])\n",
    "        non_dominant_mask = tf.reshape(non_dominant_mask, [1, num_classes])\n",
    "        \n",
    "        # Combine the weights: for each sample and each class,\n",
    "        # the weight is dominant_weight for the dominant class and non_dominant_weight for the others.\n",
    "        weights = dominant_mask * dominant_weight + non_dominant_mask * non_dominant_weight\n",
    "        \n",
    "        # Compute the weighted loss.\n",
    "        weighted_loss = base_loss * weights\n",
    "        return tf.reduce_mean(weighted_loss)\n",
    "    \n",
    "    def get_config(self):\n",
    "            config = super().get_config()\n",
    "            config.update({\n",
    "                'dominant_class_index': self.dominant_class_index,\n",
    "                'dominant_correct_multiplier': self.dominant_correct_multiplier,\n",
    "                'dominant_incorrect_multiplier': self.dominant_incorrect_multiplier,\n",
    "                'other_class_multiplier': self.other_class_multiplier,\n",
    "                'smoothing_multiplier': self.smoothing_multiplier\n",
    "            })\n",
    "            return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bfc90cc6-f645-4a10-bda8-f862fa69ab68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,648</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">184,480</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">230,560</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,640</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">415,008</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">746,784</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,648</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,368</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">426</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">54,656</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ batch_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m5\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m5\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m10\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m11,648\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m1,408\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m160\u001b[0m) │    \u001b[38;5;34m184,480\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m160\u001b[0m) │        \u001b[38;5;34m640\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m160\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m160\u001b[0m) │    \u001b[38;5;34m230,560\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m160\u001b[0m) │        \u001b[38;5;34m640\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m160\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m160\u001b[0m) │     \u001b[38;5;34m20,640\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m160\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m288\u001b[0m) │    \u001b[38;5;34m415,008\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m288\u001b[0m) │      \u001b[38;5;34m1,152\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m288\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m288\u001b[0m) │    \u001b[38;5;34m746,784\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m11,648\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m288\u001b[0m) │      \u001b[38;5;34m1,152\u001b[0m │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m288\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m288\u001b[0m) │     \u001b[38;5;34m46,368\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m288\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m426\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m54,656\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m16,512\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m, \u001b[38;5;34m5\u001b[0m)   │        \u001b[38;5;34m645\u001b[0m │ batch_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,894,085</span> (7.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,894,085\u001b[0m (7.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,891,013</span> (7.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,891,013\u001b[0m (7.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@utils.register_keras_serializable()\n",
    "def tile_to_batch(z):\n",
    "    pe, x = z\n",
    "    return tf.tile(pe, [tf.shape(x)[0], 1, 1])\n",
    "\n",
    "@utils.register_keras_serializable()\n",
    "def create_dcnn_model(\n",
    "    input_dim=5,\n",
    "    sequence_length=5000,\n",
    "    num_classes=5\n",
    "):\n",
    "    inputs = Input(shape=(sequence_length, input_dim))\n",
    "    \n",
    "    # Condensed positional encoding block.  See cnn for description\n",
    "    positions = tf.range(start=0, limit=sequence_length, delta=1)\n",
    "    pos_encoding = layers.Embedding(input_dim=sequence_length, output_dim=num_classes)(positions)\n",
    "    pos_encoding = tf.expand_dims(pos_encoding, axis=0)\n",
    "    # def tile_to_batch(z):\n",
    "    #     pe, x = z\n",
    "    #     return tf.tile(pe, [tf.shape(x)[0], 1, 1])\n",
    "    pos_encoding = layers.Lambda(tile_to_batch)([pos_encoding, inputs])\n",
    "\n",
    "    concat_input = layers.Concatenate(axis=-1)([inputs, pos_encoding])\n",
    "\n",
    "    cnn = layers.Conv1D(filters=128, kernel_size=9, activation='relu', padding='same')(concat_input)\n",
    "    cnn = layers.BatchNormalization()(cnn)\n",
    "    cnn = layers.Dropout(0.2)(cnn)\n",
    "    # We use six layers with increasing dilation rates to capture a wider receptive field.\n",
    "    # Dilating convolutional blocks with dropout (pooling is bad because exact sequence matters)\n",
    "    skip = concat_input\n",
    "    skip = layers.Conv1D(filters=128, kernel_size=1, padding='same')(skip)\n",
    "    dcnn = layers.Conv1D(filters=128, kernel_size=9, dilation_rate=1, activation='relu', padding='same')(concat_input)\n",
    "    dcnn = layers.BatchNormalization()(dcnn)\n",
    "    dcnn = layers.Dropout(0.2)(dcnn)\n",
    "    \n",
    "    dcnn = layers.Conv1D(filters=128, kernel_size=9, dilation_rate=2, activation='relu', padding='same')(dcnn)\n",
    "    dcnn = layers.BatchNormalization()(dcnn)\n",
    "    dcnn = layers.Dropout(0.2)(dcnn)\n",
    "    dcnn = layers.Add()([dcnn, skip])\n",
    "    \n",
    "    skip = dcnn\n",
    "    skip = layers.Conv1D(filters=160, kernel_size=1, padding='same')(skip)\n",
    "    dcnn = layers.Conv1D(filters=160, kernel_size=9, dilation_rate=4, activation='relu', padding='same')(dcnn)\n",
    "    dcnn = layers.BatchNormalization()(dcnn)\n",
    "    dcnn = layers.Dropout(0.2)(dcnn)\n",
    "    \n",
    "    dcnn = layers.Conv1D(filters=160, kernel_size=9, dilation_rate=8, activation='relu', padding='same')(dcnn)\n",
    "    dcnn = layers.BatchNormalization()(dcnn)\n",
    "    dcnn = layers.Dropout(0.2)(dcnn)\n",
    "    dcnn = layers.Add()([dcnn, skip])\n",
    "    \n",
    "    skip = dcnn\n",
    "    skip = layers.Conv1D(filters=288, kernel_size=1, padding='same')(skip)\n",
    "    dcnn = layers.Conv1D(filters=288, kernel_size=9, dilation_rate=16, activation='relu', padding='same')(dcnn)\n",
    "    dcnn = layers.BatchNormalization()(dcnn)\n",
    "    dcnn = layers.Dropout(0.2)(dcnn)\n",
    "    \n",
    "    dcnn = layers.Conv1D(filters=288, kernel_size=9, dilation_rate=32, activation='relu', padding='same')(dcnn)\n",
    "    dcnn = layers.BatchNormalization()(dcnn)\n",
    "    dcnn = layers.Dropout(0.2)(dcnn)\n",
    "    dcnn = layers.Add()([dcnn, skip])\n",
    "    \n",
    "    second_concat = layers.Concatenate(axis=-1)([concat_input, cnn, dcnn])\n",
    "\n",
    "    # Instead of flattening, use Conv1D with kernel_size=1 as dense layers:\n",
    "    dense = layers.Conv1D(128, kernel_size=1, activation='relu')(second_concat)\n",
    "    dense = layers.BatchNormalization()(dense)\n",
    "    dense = layers.Dropout(0.2)(dense)\n",
    "    \n",
    "    dense = layers.Conv1D(128, kernel_size=1, activation='relu')(dense)\n",
    "    dense = layers.BatchNormalization()(dense)\n",
    "\n",
    "    # Final classification layer applied at every time step:\n",
    "    outputs = layers.Conv1D(num_classes, kernel_size=1, activation='sigmoid')(dense)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "loss_fn = CustomBinaryCrossentropyLoss(\n",
    "    dominant_class_index=0,\n",
    "    dominant_correct_multiplier=0.07,\n",
    "    dominant_incorrect_multiplier=2.5,\n",
    "    other_class_multiplier=2.0,\n",
    "    smoothing_multiplier=0.5\n",
    ")\n",
    "dcnn_model = create_dcnn_model(5, 5000, 5)\n",
    "dcnn_model.compile(optimizer=optimizers.Adam(learning_rate=0.000686),\n",
    "                  loss=loss_fn,\n",
    "                  metrics=[CustomNoBackgroundF1Score(num_classes=5, average='weighted', threshold=0.5)])\n",
    "dcnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d453b3ee-0c55-4f2e-8b8a-04b46517e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_exact_records(dataset: tf.data.Dataset, total_records, num_to_drop, seed=None):\n",
    "    '''\n",
    "    Function to drop n records from data before constructing parsed dataset.  \n",
    "    Mostly for bug checking.\n",
    "    '''\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    drop_indices = set(np.random.choice(total_records, num_to_drop, replace=False))\n",
    "    dataset = dataset.enumerate()\n",
    "    dataset = dataset.filter(lambda i, x: ~tf.reduce_any(tf.equal(i, list(drop_indices))))\n",
    "    dataset = dataset.map(lambda i, x: x)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def parse_chunk_example(serialized_example):\n",
    "    \"\"\"\n",
    "    Parses a single serialized tf.train.Example back into tensors.\n",
    "    Used in testing datasets and in piping tfrecords to DL Algorithms\n",
    "    \"\"\"\n",
    "    feature_spec = {\n",
    "        'X':          tf.io.VarLenFeature(tf.float32),\n",
    "        'y':          tf.io.VarLenFeature(tf.float32),\n",
    "        'record_id':  tf.io.FixedLenFeature([], tf.string),\n",
    "        'cstart':     tf.io.FixedLenFeature([1], tf.int64),\n",
    "        'cend':       tf.io.FixedLenFeature([1], tf.int64),\n",
    "        'strand':     tf.io.FixedLenFeature([], tf.string),\n",
    "        'chunk_size': tf.io.FixedLenFeature([1], tf.int64),\n",
    "    }\n",
    "    \n",
    "    parsed = tf.io.parse_single_example(serialized_example, feature_spec)\n",
    "    \n",
    "    # chunk_size is shape [1]\n",
    "    chunk_size = parsed['chunk_size'][0]\n",
    "    \n",
    "    # Convert sparse to dense\n",
    "    X_flat = tf.sparse.to_dense(parsed['X'])\n",
    "    y_flat = tf.sparse.to_dense(parsed['y'])\n",
    "\n",
    "    # Reshape X to [chunk_size, 5]\n",
    "    X_reshaped = tf.reshape(X_flat, [chunk_size, 5])\n",
    "    # Reshape y to [chunk_size], probably redundant\n",
    "    y_reshaped = tf.reshape(y_flat, [chunk_size, 5])\n",
    "    \n",
    "    record_id = parsed['record_id']\n",
    "    cstart = parsed['cstart'][0]\n",
    "    cend = parsed['cend'][0]\n",
    "    strand = parsed['strand']\n",
    "    \n",
    "    return X_reshaped, y_reshaped, record_id, cstart, cend, strand\n",
    "\n",
    "\n",
    "def prepare_for_model(X, y, record_id, cstart, cend, strand):\n",
    "    '''\n",
    "    Helper function that extracts and reshapes parsed data for feeding to DL Models\n",
    "    '''\n",
    "    # Expand last dimension of y from (batch_size, 5000) to (batch_size, 5000, 1)\n",
    "    # y = tf.expand_dims(y, axis=-1) turns out this line is not needed\n",
    "    # Return only (X, y). Discard the extra columns for training knowing that \n",
    "    # they still exist in the TestValTrain originals if we need them\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def prep_dataset_from_tfrecord(\n",
    "    tfrecord_path,\n",
    "    batch_size=28,\n",
    "    compression_type='GZIP',\n",
    "    shuffled = False,\n",
    "    shuffle_buffer=25000,\n",
    "    total_records=None,\n",
    "    num_to_drop=None,\n",
    "    seed=None\n",
    "):\n",
    "    '''\n",
    "    Imports tfrecord and shuffles it then parses it for use in fitting a model\n",
    "    '''\n",
    "    # Loads in records in a round robin fashion for slightly increased mixing\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path, compression_type=compression_type, num_parallel_reads = tf.data.AUTOTUNE)\n",
    "    \n",
    "    if num_to_drop:\n",
    "        dataset = drop_exact_records(dataset, total_records=total_records, num_to_drop=num_to_drop, seed=seed)\n",
    "    \n",
    "    if shuffled == True:\n",
    "        # Shuffle at the record level\n",
    "        dataset = dataset.shuffle(shuffle_buffer, reshuffle_each_iteration=True)\n",
    "        \n",
    "    \n",
    "    dataset = dataset.map(parse_chunk_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(prepare_for_model, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # dataset = dataset.map(lambda x, y: (x, tf.cast(y, tf.int32))) # found out tensorflow wants int32 in y # Note: Not anymore due to change in label format\n",
    "\n",
    "    # Rebatch parsed and prefetch for efficient reading\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1864028e-06c4-4910-b05b-b8ef07e0db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "# def upload_file(file_name, bucket, object_name=None):\n",
    "#     \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "#     :param file_name: File to upload\n",
    "#     :param bucket: Bucket to upload to\n",
    "#     :param object_name: S3 object name. If not specified then file_name is used\n",
    "#     :return: True if file was uploaded, else False\n",
    "#     \"\"\"\n",
    "\n",
    "#     # If S3 object_name was not specified, use file_name\n",
    "#     if object_name is None:\n",
    "#         object_name = os.path.basename(file_name)\n",
    "\n",
    "#     # Upload the file\n",
    "#     s3_client = boto3.client('s3')\n",
    "#     try:\n",
    "#         response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "#     except ClientError as e:\n",
    "#         logging.error(e)\n",
    "#         return False\n",
    "#     return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df447960-5110-4487-ba51-329e2dd6271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLimit(callbacks.Callback):\n",
    "    def __init__(self, max_time_seconds):\n",
    "        super().__init__()\n",
    "        self.max_time_seconds = max_time_seconds\n",
    "        self.start_time = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    # def on_batch_end(self, batch, logs=None):\n",
    "    #     if time.time() - self.start_time > self.max_time_seconds:\n",
    "    #         self.model.stop_training = True\n",
    "    \n",
    "    # def on_train_batch_end(self, batch, logs=None):  # ✅ Runs more frequently than `on_batch_end`\n",
    "    #     elapsed_time = time.time() - self.start_time\n",
    "    #     if elapsed_time > self.max_time_seconds:\n",
    "    #         print(f\"\\n⏳ Time limit of {self.max_time_seconds} sec reached. Stopping training!\")\n",
    "    #         self.model.stop_training = True  # 🔥 Stops training mid-batch\n",
    "    \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        if elapsed_time > self.max_time_seconds:\n",
    "            print(f\"\\n⏳ Time limit of {self.max_time_seconds} sec reached. Stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):  # New method added\n",
    "        if time.time() - self.start_time > self.max_time_seconds:\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "class DebugCallback(callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\n🚀 Starting Epoch {epoch+1}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if batch % 1000 == 0:\n",
    "            print(f\"🔄 Processing Batch {batch}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if batch % 1000 == 0:\n",
    "            print(f\"✅ Finished Batch {batch}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\n🏁 Epoch {epoch+1} Completed!\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "class CleanupCallback(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Example: force garbage collection\n",
    "        gc.collect()\n",
    "\n",
    "        # If you need more extensive cleanup, you can add it here.\n",
    "        # e.g., close files, flush logs, free external resources, etc.\n",
    "        print(f\"Cleanup done at the end of epoch {epoch+1}\")\n",
    "        \n",
    "\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "    filepath= models_path + 'checkpoints/epoch-{epoch:03d}-val_loss-{val_loss:.4f}.keras',\n",
    "    monitor='val_loss',          # what metric to name file on\n",
    "    save_best_only=False,        # save model always \n",
    "    save_weights_only=False,     # save full model (architecture + weights)\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "# class UploadModelCheckpoint(callbacks.ModelCheckpoint):\n",
    "#     \"\"\"\n",
    "#     A custom ModelCheckpoint callback that, when a new best model is saved,\n",
    "#     calls the upload_file function to upload the saved model.\n",
    "    \n",
    "#     Inherits from tf.keras.callbacks.ModelCheckpoint.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, bucket, object_name=None, **kwargs):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             bucket (str): The bucket where the file should be uploaded.\n",
    "#             object_name (str, optional): The object name to use when uploading.\n",
    "#             **kwargs: All other keyword arguments for ModelCheckpoint.\n",
    "#         \"\"\"\n",
    "#         super(UploadModelCheckpoint, self).__init__(**kwargs)\n",
    "#         self.bucket = bucket\n",
    "#         self.object_name = object_name\n",
    "\n",
    "#     def _save_model(self, epoch, logs):\n",
    "#         \"\"\"\n",
    "#         Overrides the internal _save_model method. First saves the model as usual,\n",
    "#         then calls upload_file with the saved file's path.\n",
    "#         \"\"\"\n",
    "#         # Get the file path using the parent's filepath formatting\n",
    "#         filepath = self._get_file_path(epoch, logs)\n",
    "#         # Save the model as usual\n",
    "#         super(UploadModelCheckpoint, self)._save_model(epoch, logs)\n",
    "#         # Now call the upload function with the saved file\n",
    "#         upload_file(filepath, self.bucket, self.object_name)\n",
    "\n",
    "\n",
    "# checkpoint_cb = UploadModelCheckpoint(\n",
    "#     bucket=s3_bucket,  # The bucket to which files are uploaded\n",
    "#     object_name='checkpoints/recent_best_model.keras',         # Optional: if not provided, the local file name will be used as the object name\n",
    "#     filepath='checkpoints/recent_best_model.keras',\n",
    "#     monitor='val_loss',       # The metric to monitor\n",
    "#     save_best_only=True,      # Only save when a new best is reached\n",
    "#     save_weights_only=False,  # Save the full model (architecture + weights)\n",
    "#     save_freq='epoch'\n",
    "# )\n",
    "\n",
    "\n",
    "early_stopping_cb = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    min_delta=1e-4,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e705ce-c5a8-45f6-be96-adeed04e3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(False)\n",
    "# # Train: 200985, Val: 23645, Test: 11824    \n",
    "# max_time_seconds = 3600*12  # 1 hour is 3600 seconds\n",
    "# batch_size = 28\n",
    "# epochs = 400  # Set high enough to allow stopping by callback\n",
    "# steps_per_epoch = 7178\n",
    "\n",
    "# print('Compiling train dataset')\n",
    "# train_dataset = prep_dataset_from_tfrecord(datasets_path + \"TestValTrain/train.tfrecord.gz\",\n",
    "#                                 batch_size=batch_size, \n",
    "#                                 compression_type='GZIP', \n",
    "#                                 shuffled=True,\n",
    "#                                 shuffle_buffer=10000,\n",
    "#                                 total_records=200985,\n",
    "#                                 num_to_drop=1 # Batch size 28 leaves remainder of 1 record\n",
    "#                                 )\n",
    "# train_dataset = train_dataset.repeat()\n",
    "\n",
    "# print('Compiling val dataset')\n",
    "# val_dataset = prep_dataset_from_tfrecord(datasets_path + \"TestValTrain/val.tfrecord.gz\",\n",
    "#                                 batch_size=batch_size, \n",
    "#                                 compression_type='GZIP', \n",
    "#                                 shuffled=False,\n",
    "#                                 shuffle_buffer=5000,\n",
    "#                                 total_records=23645,\n",
    "#                                 num_to_drop=13, # Batch size 28 leaves remainder of 13 records\n",
    "#                                 seed=42 # Seed for dropping the same 13 records every time\n",
    "#                                 )\n",
    "\n",
    "# # test_dataset = prep_dataset_from_tfrecord(datasets_path + \"TestValTrain/test.tfrecord.gz\",\n",
    "# #                                 batch_size=batch_size, \n",
    "# #                                 compression_type='GZIP', \n",
    "# #                                 shuffled=False,\n",
    "# #                                 shuffle_buffer=5000,\n",
    "# #                                 total_records=11824,\n",
    "# #                                 num_to_drop=8, # Batch size 28 leaves remainder of 13 records\n",
    "# #                                 seed=42 # Seed for dropping the same 8 records every time\n",
    "# #                                 )\n",
    "\n",
    "# # history = dcnn_model.fit(\n",
    "# #         train_dataset, \n",
    "# #         validation_data=val_dataset,\n",
    "# #         # batch_size=batch_size,\n",
    "# #         epochs=epochs,\n",
    "# #         steps_per_epoch=steps_per_epoch,\n",
    "# #         callbacks=[early_stopping_cb, checkpoint_cb, CleanupCallback(), TimeLimit(max_time_seconds=max_time_seconds)]\n",
    "# #         )\n",
    "\n",
    "# # print('Saving model...')\n",
    "# # dcnn_model.save(\"Finished_Model.keras\")\n",
    "# # # upload_file(\"Finished_Model.keras\", s3_bucket, \"checkpoints/Finished_Model.keras)\n",
    "# # print(f\"📁 Model saved!\")\n",
    "\n",
    "\n",
    "# loss_fn = CustomBinaryCrossentropyLoss(\n",
    "#     dominant_class_index=0,\n",
    "#     dominant_correct_multiplier=0.07,\n",
    "#     dominant_incorrect_multiplier=2.5,\n",
    "#     other_class_multiplier=2.0,\n",
    "#     smoothing_multiplier=0.5\n",
    "# )\n",
    "\n",
    "# # Define your checkpoint directory and file pattern.\n",
    "# checkpoint_dir = models_path + \"checkpoints\"\n",
    "# # Assume your checkpoint files follow the pattern 'cp-XXXX.ckpt'\n",
    "# checkpoint_pattern = os.path.join(checkpoint_dir, \"epoch-*-val_loss-*.keras\")\n",
    "\n",
    "# # Find the most recent checkpoint file.\n",
    "# checkpoint_files = glob.glob(checkpoint_pattern)\n",
    "# if checkpoint_files:\n",
    "#     latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
    "#     print(\"Resuming from checkpoint:\", latest_checkpoint)\n",
    "    \n",
    "#     # Load the entire model from the checkpoint.\n",
    "#     dcnn_model = models.load_model(latest_checkpoint)\n",
    "#     dcnn_model.compile(\n",
    "#                         loss=loss_fn,\n",
    "#                         metrics=[\n",
    "#                             CustomNoBackgroundF1Score(num_classes=5, average='weighted', threshold=0.5),\n",
    "#                             CustomNoBackgroundF1Score(num_classes=5, average='macro', threshold=0.5),\n",
    "#                             CustomBackgroundOnlyF1Score(num_classes=5, average='weighted', threshold=0.5),\n",
    "#                             CustomBackgroundOnlyF1Score(num_classes=5, average='macro', threshold=0.5)\n",
    "#                             ]\n",
    "#                        )\n",
    "    \n",
    "#     epoch_str = os.path.basename(latest_checkpoint).split('-')[1]\n",
    "#     # Remove any file extension; adjust the splitting as needed.\n",
    "#     epoch_num = int(''.join(filter(str.isdigit, epoch_str)))\n",
    "#     initial_epoch = epoch_num\n",
    "# else:\n",
    "#     print(\"No checkpoint found. Starting training from scratch.\")\n",
    "#     # Build and compile your model as you normally do.\n",
    "#     dcnn_model = create_dcnn_model(5, 5000, 5)\n",
    "#     dcnn_model.compile(\n",
    "#                     optimizer=optimizers.Adam(learning_rate=0.000686),\n",
    "#                     loss=loss_fn,\n",
    "#                     metrics=[\n",
    "#                         CustomNoBackgroundF1Score(num_classes=5, average='weighted', threshold=0.5),\n",
    "#                         CustomNoBackgroundF1Score(num_classes=5, average='macro', threshold=0.5),\n",
    "#                         CustomBackgroundOnlyF1Score(num_classes=5, average='weighted', threshold=0.5),\n",
    "#                         CustomBackgroundOnlyF1Score(num_classes=5, average='macro', threshold=0.5)\n",
    "#                         ]\n",
    "#                     )\n",
    "#     dcnn_model.summary()\n",
    "#     initial_epoch = 0\n",
    "\n",
    "# # Continue training.\n",
    "# history = dcnn_model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset,\n",
    "#     epochs=epochs,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     callbacks=[early_stopping_cb, checkpoint_cb, CleanupCallback(), TimeLimit(max_time_seconds=max_time_seconds)],\n",
    "#     initial_epoch=initial_epoch  # This tells Keras to start counting epochs from here.\n",
    "# )\n",
    "\n",
    "# # Save final model if needed.\n",
    "# dcnn_model.save(models_path + \"Finished_Model.keras\")\n",
    "# print(\"📁 Model saved!\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3739fdfc",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35835b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling val dataset\n",
      "Evaluating epoch-001-val_loss-0.0263.keras...\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 41ms/step - background_only_f1: 0.9988 - background_only_f1_1: 0.9988 - loss: 0.0265 - no_background_f1: 0.4207 - no_background_f1_1: 0.4303\n",
      "Evaluating epoch-003-val_loss-0.0247.keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:10:57.932497: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2002610089650243901\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - background_only_f1: 0.9988 - background_only_f1_1: 0.9988 - loss: 0.0249 - no_background_f1: 0.3717 - no_background_f1_1: 0.3765\n",
      "Evaluating epoch-004-val_loss-0.0244.keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:11:35.074019: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - background_only_f1: 0.9989 - background_only_f1_1: 0.9989 - loss: 0.0245 - no_background_f1: 0.5163 - no_background_f1_1: 0.5209\n",
      "Evaluating epoch-005-val_loss-0.0243.keras...\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - background_only_f1: 0.9988 - background_only_f1_1: 0.9988 - loss: 0.0244 - no_background_f1: 0.5009 - no_background_f1_1: 0.5118\n",
      "Evaluating epoch-006-val_loss-0.0241.keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:12:49.209096: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2002610089650243901\n",
      "2025-02-13 17:12:49.209184: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2528053032855672444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - background_only_f1: 0.9988 - background_only_f1_1: 0.9988 - loss: 0.0243 - no_background_f1: 0.4140 - no_background_f1_1: 0.4236\n",
      "Evaluating epoch-007-val_loss-0.0240.keras...\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - background_only_f1: 0.9987 - background_only_f1_1: 0.9987 - loss: 0.0242 - no_background_f1: 0.4610 - no_background_f1_1: 0.4702\n",
      "Evaluating epoch-008-val_loss-0.0241.keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:14:04.028875: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 43ms/step - background_only_f1: 0.9988 - background_only_f1_1: 0.9988 - loss: 0.0242 - no_background_f1: 0.4353 - no_background_f1_1: 0.4431\n",
      "Evaluating epoch-009-val_loss-0.0240.keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:14:41.839994: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2002610089650243901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - background_only_f1: 0.9987 - background_only_f1_1: 0.9987 - loss: 0.0241 - no_background_f1: 0.4750 - no_background_f1_1: 0.4860\n",
      "Evaluating epoch-010-val_loss-0.0240.keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:15:20.586088: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2002610089650243901\n",
      "2025-02-13 17:15:20.586155: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2528053032855672444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - background_only_f1: 0.9987 - background_only_f1_1: 0.9987 - loss: 0.0241 - no_background_f1: 0.4531 - no_background_f1_1: 0.4645\n",
      "Evaluating epoch-011-val_loss-0.0243.keras...\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - background_only_f1: 0.9989 - background_only_f1_1: 0.9989 - loss: 0.0244 - no_background_f1: 0.5004 - no_background_f1_1: 0.5101\n",
      "Evaluating epoch-012-val_loss-0.0240.keras...\n",
      "\u001b[1m843/843\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 43ms/step - background_only_f1: 0.9988 - background_only_f1_1: 0.9988 - loss: 0.0241 - no_background_f1: 0.4848 - no_background_f1_1: 0.4919\n",
      "Evaluating epoch-013-val_loss-0.0240.keras...\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - background_only_f1: 0.9987 - background_only_f1_1: 0.9987 - loss: 0.0241 - no_background_f1: 0.4946 - no_background_f1_1: 0.5057\n",
      "Evaluating epoch-016-val_loss-0.0240.keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:17:51.126163: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2528053032855672444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 43ms/step - background_only_f1: 0.9987 - background_only_f1_1: 0.9987 - loss: 0.0241 - no_background_f1: 0.4760 - no_background_f1_1: 0.4899\n",
      "                         Checkpoint  \\\n",
      "0   epoch-001-val_loss-0.0263.keras   \n",
      "1   epoch-003-val_loss-0.0247.keras   \n",
      "2   epoch-004-val_loss-0.0244.keras   \n",
      "3   epoch-005-val_loss-0.0243.keras   \n",
      "4   epoch-006-val_loss-0.0241.keras   \n",
      "5   epoch-007-val_loss-0.0240.keras   \n",
      "6   epoch-008-val_loss-0.0241.keras   \n",
      "7   epoch-009-val_loss-0.0240.keras   \n",
      "8   epoch-010-val_loss-0.0240.keras   \n",
      "9   epoch-011-val_loss-0.0243.keras   \n",
      "10  epoch-012-val_loss-0.0240.keras   \n",
      "11  epoch-013-val_loss-0.0240.keras   \n",
      "12  epoch-016-val_loss-0.0240.keras   \n",
      "\n",
      "                                              Results  \n",
      "0   [0.02629547193646431, 0.4233812093734741, 0.42...  \n",
      "1   [0.02472471073269844, 0.37515681982040405, 0.3...  \n",
      "2   [0.02436007373034954, 0.518424928188324, 0.518...  \n",
      "3   [0.024295059964060783, 0.5021491050720215, 0.5...  \n",
      "4   [0.024132538586854935, 0.41637763381004333, 0....  \n",
      "5   [0.024034935981035233, 0.4626420736312866, 0.4...  \n",
      "6   [0.024082716554403305, 0.4362534284591675, 0.4...  \n",
      "7   [0.02401990070939064, 0.4754262864589691, 0.47...  \n",
      "8   [0.02400152012705803, 0.45425015687942505, 0.4...  \n",
      "9   [0.024292444810271263, 0.5033577084541321, 0.5...  \n",
      "10  [0.02401198446750641, 0.4855882227420807, 0.48...  \n",
      "11  [0.02396787889301777, 0.495547354221344, 0.495...  \n",
      "12  [0.023957543075084686, 0.47803619503974915, 0....  \n",
      "Validation results saved to 'validation_results.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:18:29.160182: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2002610089650243901\n",
      "2025-02-13 17:18:29.160245: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2528053032855672444\n"
     ]
    }
   ],
   "source": [
    "max_time_seconds = 3600*12  # 1 hour is 3600 seconds\n",
    "batch_size = 28\n",
    "epochs = 400  # Set high enough to allow stopping by callback\n",
    "steps_per_epoch = 7178\n",
    "\n",
    "# print('Compiling train dataset')\n",
    "# train_dataset = prep_dataset_from_tfrecord(datasets_path + \"TestValTrain/train.tfrecord.gz\",\n",
    "#                                 batch_size=batch_size, \n",
    "#                                 compression_type='GZIP', \n",
    "#                                 shuffled=True,\n",
    "#                                 shuffle_buffer=10000,\n",
    "#                                 total_records=200985,\n",
    "#                                 num_to_drop=1 # Batch size 28 leaves remainder of 1 record\n",
    "#                                 )\n",
    "# train_dataset = train_dataset.repeat()\n",
    "\n",
    "print('Compiling val dataset')\n",
    "val_dataset = prep_dataset_from_tfrecord(datasets_path + \"TestValTrain/val.tfrecord.gz\",\n",
    "                                batch_size=batch_size, \n",
    "                                compression_type='GZIP', \n",
    "                                shuffled=False,\n",
    "                                shuffle_buffer=5000,\n",
    "                                total_records=23645,\n",
    "                                num_to_drop=13, # Batch size 28 leaves remainder of 13 records\n",
    "                                seed=42 # Seed for dropping the same 13 records every time\n",
    "                                )\n",
    "# val_dataset = val_dataset.repeat()\n",
    "# test_dataset = prep_dataset_from_tfrecord(datasets_path + \"TestValTrain/test.tfrecord.gz\",\n",
    "#                                 batch_size=batch_size, \n",
    "#                                 compression_type='GZIP', \n",
    "#                                 shuffled=False,\n",
    "#                                 shuffle_buffer=5000,\n",
    "#                                 total_records=11824,\n",
    "#                                 num_to_drop=8, # Batch size 28 leaves remainder of 13 records\n",
    "#                                 seed=42 # Seed for dropping the same 8 records every time\n",
    "#                                 )\n",
    "\n",
    "# history = dcnn_model.fit(\n",
    "#         train_dataset, \n",
    "#         validation_data=val_dataset,\n",
    "#         # batch_size=batch_size,\n",
    "#         epochs=epochs,\n",
    "#         steps_per_epoch=steps_per_epoch,\n",
    "#         callbacks=[early_stopping_cb, checkpoint_cb, CleanupCallback(), TimeLimit(max_time_seconds=max_time_seconds)]\n",
    "#         )\n",
    "\n",
    "# print('Saving model...')\n",
    "# dcnn_model.save(\"Finished_Model.keras\")\n",
    "# # upload_file(\"Finished_Model.keras\", s3_bucket, \"checkpoints/Finished_Model.keras)\n",
    "# print(f\"📁 Model saved!\")\n",
    "\n",
    "\n",
    "loss_fn = CustomBinaryCrossentropyLoss(\n",
    "    dominant_class_index=0,\n",
    "    dominant_correct_multiplier=0.07,\n",
    "    dominant_incorrect_multiplier=2.5,\n",
    "    other_class_multiplier=2.0,\n",
    "    smoothing_multiplier=0.5\n",
    ")\n",
    "\n",
    "# Define your checkpoint directory\n",
    "checkpoint_dir = models_path + \"checkpoints\"\n",
    "\n",
    "# Store results in a list\n",
    "results_list = []\n",
    "\n",
    "# Loop through all saved model files\n",
    "for filename in sorted(os.listdir(checkpoint_dir)):  # Ensure sorted order\n",
    "    if filename.endswith(\".keras\"):  # Adjust if using TensorFlow checkpoints\n",
    "        model_path = os.path.join(checkpoint_dir, filename)\n",
    "        print(f\"Evaluating {filename}...\")\n",
    "\n",
    "        # Load the model (Include custom loss/metrics if necessary)\n",
    "        model = models.load_model(model_path) \n",
    "        model.compile(\n",
    "                    loss=loss_fn,\n",
    "                    metrics=[\n",
    "                        CustomNoBackgroundF1Score(num_classes=5, average='weighted', threshold=0.5),\n",
    "                        CustomNoBackgroundF1Score(num_classes=5, average='macro', threshold=0.5),\n",
    "                        CustomBackgroundOnlyF1Score(num_classes=5, average='weighted', threshold=0.5),\n",
    "                        CustomBackgroundOnlyF1Score(num_classes=5, average='macro', threshold=0.5)\n",
    "                        ]\n",
    "                    )\n",
    "            \n",
    "\n",
    "        # Evaluate on validation dataset\n",
    "        results = model.evaluate(val_dataset, verbose=1)  # Suppress output\n",
    "\n",
    "        # Store results (Modify column names as needed)\n",
    "        results_list.append({\"Checkpoint\": filename, \"Results\" : results})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df_results = pd.DataFrame(results_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_results)\n",
    "\n",
    "# Save the DataFrame to a CSV file for later analysis\n",
    "df_results.to_csv(models_path + \"Results/validation_results.csv\", index=False)\n",
    "\n",
    "print(\"Validation results saved to 'Results/validation_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0bc6ffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Checkpoint': 'epoch-001-val_loss-0.0263.keras', 'Results': [0.02629547193646431, 0.4233812093734741, 0.4233812093734741, 0.9988483190536499, 0.9988483190536499, 0.9988483190536499, 0.4332113564014435]}, {'Checkpoint': 'epoch-003-val_loss-0.0247.keras', 'Results': [0.02472471073269844, 0.37515681982040405, 0.37515681982040405, 0.9988055229187012, 0.9988055229187012, 0.9988055229187012, 0.3802448809146881]}, {'Checkpoint': 'epoch-004-val_loss-0.0244.keras', 'Results': [0.02436007373034954, 0.518424928188324, 0.518424928188324, 0.9988994598388672, 0.9988994598388672, 0.9988994002342224, 0.5233819484710693]}, {'Checkpoint': 'epoch-005-val_loss-0.0243.keras', 'Results': [0.024295059964060783, 0.5021491050720215, 0.5021491050720215, 0.9988505244255066, 0.9988505244255066, 0.9988505244255066, 0.5132834911346436]}, {'Checkpoint': 'epoch-006-val_loss-0.0241.keras', 'Results': [0.024132538586854935, 0.41637763381004333, 0.41637763381004333, 0.9988260269165039, 0.9988260269165039, 0.9988260269165039, 0.42628878355026245]}, {'Checkpoint': 'epoch-007-val_loss-0.0240.keras', 'Results': [0.024034935981035233, 0.4626420736312866, 0.4626420736312866, 0.9987021684646606, 0.9987021684646606, 0.9987021684646606, 0.47210386395454407]}, {'Checkpoint': 'epoch-008-val_loss-0.0241.keras', 'Results': [0.024082716554403305, 0.4362534284591675, 0.4362534284591675, 0.9988309144973755, 0.9988309144973755, 0.9988309144973755, 0.4443570375442505]}, {'Checkpoint': 'epoch-009-val_loss-0.0240.keras', 'Results': [0.02401990070939064, 0.4754262864589691, 0.4754262864589691, 0.9987407326698303, 0.9987407326698303, 0.9987407326698303, 0.48662564158439636]}, {'Checkpoint': 'epoch-010-val_loss-0.0240.keras', 'Results': [0.02400152012705803, 0.45425015687942505, 0.45425015687942505, 0.9987397789955139, 0.9987397789955139, 0.9987397789955139, 0.46593669056892395]}, {'Checkpoint': 'epoch-011-val_loss-0.0243.keras', 'Results': [0.024292444810271263, 0.5033577084541321, 0.5033577084541321, 0.9989486336708069, 0.9989486336708069, 0.9989486336708069, 0.5133631229400635]}, {'Checkpoint': 'epoch-012-val_loss-0.0240.keras', 'Results': [0.02401198446750641, 0.4855882227420807, 0.4855882227420807, 0.9988089203834534, 0.9988089203834534, 0.9988089203834534, 0.49280065298080444]}, {'Checkpoint': 'epoch-013-val_loss-0.0240.keras', 'Results': [0.02396787889301777, 0.495547354221344, 0.495547354221344, 0.9987152814865112, 0.9987152814865112, 0.9987152814865112, 0.5069794654846191]}, {'Checkpoint': 'epoch-016-val_loss-0.0240.keras', 'Results': [0.023957543075084686, 0.47803619503974915, 0.47803619503974915, 0.9987313747406006, 0.9987313747406006, 0.9987313747406006, 0.49239155650138855]}]\n"
     ]
    }
   ],
   "source": [
    "print(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6be1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define your checkpoint directory and file pattern.\n",
    "# checkpoint_dir = models_path + \"checkpoints\"\n",
    "# # Assume your checkpoint files follow the pattern 'cp-XXXX.ckpt'\n",
    "# checkpoint_pattern = os.path.join(checkpoint_dir, \"epoch-*-val_loss-*.keras\")\n",
    "\n",
    "# # Find the most recent checkpoint file.\n",
    "# checkpoint_files = glob.glob(checkpoint_pattern)\n",
    "# if checkpoint_files:\n",
    "#     latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
    "#     print(\"Resuming from checkpoint:\", latest_checkpoint)\n",
    "    \n",
    "#     # Load the entire model from the checkpoint.\n",
    "#     dcnn_model = models.load_model(latest_checkpoint)\n",
    "#     dcnn_model.compile()\n",
    "    \n",
    "#     epoch_str = os.path.basename(latest_checkpoint).split('-')[1]\n",
    "#     # Remove any file extension; adjust the splitting as needed.\n",
    "#     epoch_num = int(''.join(filter(str.isdigit, epoch_str)))\n",
    "#     initial_epoch = epoch_num\n",
    "# else:\n",
    "#     print(\"No checkpoint found. Starting training from scratch.\")\n",
    "#     # Build and compile your model as you normally do.\n",
    "#     dcnn_model = create_dcnn_model(5, 5000, 5)\n",
    "#     dcnn_model.compile(optimizer=optimizers.Adam(learning_rate=0.000686),\n",
    "#                     loss=custom_binary_crossentropy_loss(\n",
    "#                         dominant_class_index=0,\n",
    "#                         dominant_correct_multiplier=0.07,\n",
    "#                         dominant_incorrect_multiplier=2.5,\n",
    "#                         other_class_multiplier=2.0,\n",
    "#                         smoothing_multiplier=0.5\n",
    "#                     ),\n",
    "#                     metrics=[\n",
    "#                         CustomNoBackgroundF1Score(num_classes=5, average='weighted', threshold=0.5),\n",
    "#                         CustomNoBackgroundF1Score(num_classes=5, average='macro', threshold=0.5),\n",
    "#                         CustomBackgroundOnlyF1Score(num_classes=5, average='weighted', threshold=0.5),\n",
    "#                         CustomBackgroundOnlyF1Score(num_classes=5, average='macro', threshold=0.5)\n",
    "#                         ]\n",
    "#                     )\n",
    "#     dcnn_model.summary()\n",
    "#     initial_epoch = 0\n",
    "\n",
    "# # Continue training.\n",
    "# history = dcnn_model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset,\n",
    "#     epochs=epochs,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     callbacks=[early_stopping_cb, checkpoint_cb, CleanupCallback(), TimeLimit(max_time_seconds=max_time_seconds)],\n",
    "#     initial_epoch=initial_epoch  # This tells Keras to start counting epochs from here.\n",
    "# )\n",
    "\n",
    "# # Save final model if needed.\n",
    "# dcnn_model.save(\"Finished_Model.keras\")\n",
    "# print(\"📁 Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e58e17a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'summarize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'summarize'"
     ]
    }
   ],
   "source": [
    "dcnn_model.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff6beb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
